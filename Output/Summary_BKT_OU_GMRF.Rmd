---
title: "Summary of Simulations and Analysis of Brook Trout Data"
author: "Daniel Hocking"
date: "November 20, 2015"
output: html_document
---


```{r load libraries, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
library(TMB)
library(dplyr)
library(tidyr)
library(ggplot2)
#source("Functions/summary_functions.R")

```

## Effects of Sampling Density

```{r load sample density, echo=FALSE, results='hide'}
density_inputs <- readRDS("survey_density_input.RData")
density_results <- readRDS("survey_density_results.RData")
```

### Methods

To understand how well the model worked and how much data is necessary to fit the model, I simulated data on the White River network from VT. The network is a HUC8 (01080105) with 335 confluence and terminal nodes and in additional 25 nodes from survey locations. The mean hydrologic distance between nodes was 1.13 km with a range of 0.016 to 5.13 km.

I varied the proportion of the nodes surveyed as: `r density_inputs$sample_pct_vec`, which corresponds to `r density_inputs$sample_pct_vec*length(density_inputs$network$x_b)` survey locations, respectively. I assumed constant moderate spatial autocorrelation with $\theta =$ `r density_inputs$theta` and $\sigma_{OU} =$ `r density_inputs$SD` and simulated the network with a mean of `r density_inputs$mean_N` fish per location (node). This is a typical expected density of adult brook trout for a 100 m stream reach in this area. I included one covariate on abundance ($\gamma =$ `r density_inputs$gamma`), which was not spatially correlated. The detection probability was assumed to be constant across sites and represented 3-pass depletion sampling (75% probability of individual detection per pass: $p_{pass} =$ `r density_inputs$p`).

### Results

Mean estimates of abundance improved with increasing sample size. This is evidenced by the decreasing root mean squared error (RMSE) with increasing sample size.

```{r rmse density, echo=FALSE}
format(density_results$df_err, digits = 2)

N_means <- density_results$coef_means %>%
  dplyr::filter(grepl("N_", param)) %>%
  dplyr::select(-param) %>%
  colMeans() # not very interesting

```

Not surprisingly, the precision of the abundance estimates increased with sample size. The mean standard deviations of the abundance estimates were:

```{r, echo=FALSE}
sd_pct_N <- density_results$sd_pct %>%
  dplyr::filter(grepl("N_", param)) %>%
  dplyr::select(-param) %>%
  dplyr::summarise_each(funs(mean))

format(sd_pct_N, digits = 3)
```

However, there was some bias in all scenarios with the model overestimating abundance when true abundance was low and underestimating when abundance was high. This bais was much greater at low sample sizes.

![](pct1.pdf)
![](pct0.5.pdf)
![](pct0.25.pdf)
![](pct0.1.pdf)
![](pct0.05.pdf)


The coefficient on abundance was recovered very well at all survey densities, with the execption of a moderate underestimation when only 5% of the sites were sampled.

```{r density coef means, echo=FALSE}
coef_means <- density_results$coef_means %>%
  dplyr::filter(!grepl("N_", param),
                !(param %in% c("log_theta_st",
                               "rhot",
                               "SD_report")))
format(coef_means, digits = 2)
```

However, the uncertainty in the estimate decreased with sample size.
 
```{r density coef sd, echo=FALSE}
sd_pct_coef <- density_results$sd_pct %>%
  dplyr::filter(!grepl("N_", param),
                !(param %in% c("log_theta_st",
                               "rhot",
                               "SD_report")))
format(sd_pct_coef, digits = 2)
```

As seen above the correlation decay rate with distance, $\theta$, and the variability in correlation, $\sigma_{OU}$ were not recovered well at all in the simulations. It is likely that these parameters are not separable. However, in combination, they may improve estimates compared to nonspatially explicit models. This motivated additional simulations (see below).

### Discussion

It is unclear how important the density of sampling is (this was randomly distibuted within the network) and whether percent of the nodes is more important than just the absolute number (or density) of sampled sites.

I don't know that it's really worth doing extensive simulations to get at the differences unless we wanted to write a separate paper on optimal sample design.

I also did not include any random site-level overdispersion or any temporal patterns.


## Effect of Spatial Correlation and Population Size

```{r load sim results, echo=FALSE, results='hide'}
sim_inputs <- readRDS("spatial_sims_input.RData")
sim_table <- readRDS("Sim_Table.RData")
```

To understand how our spatial model performs compared to a conventional non-spatially explicit model, we simulated data in the same network described above varying the spatial nature of the data. We simulated data with and without spatial structure. When spatial structure was present it followed an Ornstein-Uhlenbeck process and we varied all combinations of $\theta$ (`r sim_inputs$theta_vec`) and $\sigma_{OU}$ (`r sim_inputs$SD_vec`). We also varied these in combination with the mean population size across the network (`r sim_inputs$mean_N`).

We checked for model convergence then compared AIC and RMSE as well as the ability to recover the covariate effect (coefficient) and the standard deviation of the coefficient.

### Results

(large theta and small SD_ou = higher spatial correlation)

Not surprisingly, we found that spatial models always perform better on spatially autocorrelated data compared with non-spatial models. With spatial data, both the spatial and nonspatial modesl converged 96% of the time. When the data had no spatial correlation, the nonspatial model converged 100% of the time whereas the spatial model only converged in 26% of cases.

```{r sim table fit, echo=FALSE}
tab1 <- dplyr::select(sim_table, -resid_mean, -theta_hat, -SD_ou_hat, -coef_hat, -coef_sd, -coef_true, -model)
format(tab1, digits = 2)

tab1_sum <- tab1 %>%
  dplyr::group_by(spatial, sp_mod) %>%
  dplyr::select(-theta, -SD_ou, -mean_N) %>%
  dplyr::summarise_each(funs(mean(., na.rm = TRUE)))
format(tab1_sum, digits = 2)
```

In contrast, the coefficient of abundance was recovered about equally well using spatial and non-spatial models. This was the case for both the mean estimate and the variance of the coefficient estimate. We only used a single covariate and had not overdispersion, therefore this result might not be the same with more complex data. 

As with the sampling density simulations, $\theta$ and $\sigma_{OU}$ were not estimated well at all. It is likely the parameters are not separable, but together they do appear to significantly improve estimates of abundance.

```{r sim table fit 2, echo=FALSE}
tab2 <- dplyr::select(sim_table, -AIC, -rmse, -resid_mean, -coef_true, -model)
format(dplyr::select(tab2, -coef_hat, -coef_sd), digits = 2)

tab2_sum <- tab2 %>%
  dplyr::group_by(spatial, sp_mod) %>%
  dplyr::select(-mean_N) %>%
  dplyr::summarise_each(funs(mean(., na.rm = TRUE)))
format(tab2_sum, digits = 2)
```

Plots to check for bias:

![](model_34.pdf)
![](model_36.pdf)
![](model_33.pdf)
![](model_35.pdf)

Unlike with the previous simulations, there is no bias in the abundance estimates from the spatial model. The difference might be larger mean abundance and/or stronger spatial autocorrelation in the data.

### Discussion

All data were assumed to have come from a single year. There was no temporal or spatiotemporal variation in our simulations. Additionally, we did not vary abundance randomly by site beyond the Poisson distribution (no random IID overdispersion) nor did we vary the probability of detection.

Spatial models clearly do better when there is unaccounted for spatial correlation in the data. This is likely to be the case in many stream fish datasets. The difference increases with higher levels of correlation. When there is no spatial correlation, the spatial model often fails to converge. When it does converge the non-spatial model generally has a lower AIC. When there was no underlying spatial correlation, the estimates of abundance and coefficients from the spatial model also showed no systematic bias and minimal difference in the error compared with the nonspatial model. This suggests that there is little if any risk of using a spatially explicit model and comparing it to a nonspatial model. 

This method does not require special GIS skills or extensive processing. The only information needed beyond that of a traditional model is hydrologic distances between each downstream point and the nearest upstream confluences or points of interest.

It currently doesn't seem worth doing more complicated simulations for a first paper. It would muddle the message too much. The question is whether any simulations are necessary. Also, I only ran a single realization of each simulation. If we think this is a valuable part of a manuscript we would want to decide if that's enough or if we need to do many iterations of the simulations



## Applied to West Susquehanna Data

Data from the PA Fish and Boat Commission.

### Adults

```{r load west susquehanna adult results, echo=FALSE, results='hide'}
adult_inputs <- readRDS("spatial_sims_input.RData")
#adult_results <- readRDS("W_Susquehanna_Summary.RData")
load("W_Susquehanna.RData")
```

### Methods

Data from the PA Fish and Boat Commission.

### Results

```{r adult aic, echo=FALSE}
format(aic_table, digits = 2)
```

Coefficients of the top model:

```{r adult best model summary, echo=FALSE}
LCI <- SD5b$value - (1.96 * SD5b$sd) # lower CI rough estimate for best model
UCI <- SD5b$value + (1.96 * SD5b$sd)

coef_table <- data.frame(Parameter = names(SD5b$value), Estimate = SD5b$value, SD = SD5b$sd, LCI, UCI, stringsAsFactors = FALSE)
coef_table$Parameter <- SD_table$Parameter

format(coef_table, digits = 2, scientific = 5)
```

### Plot adult observed vs expected

```{r observed vs expected adult, echo=FALSE}
c_ip <- df %>%
  dplyr::select(starts_with("pass"))

chat_ip <- Report5b$chat_ip
bar <- data.frame(chat_ip, row = 1:nrow(chat_ip))
bar <- gather(bar, key = row, value = chat, convert = TRUE)
sna <- data.frame(c_ip)
fu <- sna %>% gather(pass, count)
df_counts <- data.frame(fu, bar)
df_counts <- dplyr::filter(df_counts, complete.cases(df_counts))
ggplot(df_counts, aes(count, chat)) + geom_point() + geom_abline(aes(0,1), colour = "blue") + theme_bw() + xlab("Observed adult counts per pass") + ylab("Expected adult counts per pass")

rmse <- function(error, na.rm = T) {
  sqrt(mean(error^2, na.rm = T))
}
rmse <- rmse(df_counts$count - df_counts$chat)

```

The RMSE of observed - expected adult counts is `r format(rmse, digits=2)`. There is no observed bias in the predicted counts compared with the observed counts.

### Plot adult predictions

Mean predicted abundance over time at each site with observed data (not currently adjusted using the site-visit level overdispersion).

```{r plot adult predictions, echo=FALSE}
# Plot predictions
length_sample <- df$length_sample
length_sample[which(is.na(length_sample))] <- median(df$length_sample, na.rm = TRUE)
df$N <- Report5b$N_ip[ , 1]/length_sample*100

df_observed <- df %>%
  dplyr::filter(!is.na(pass_1))

lambda_dt <- data.frame(Report5b$lambda_dt)
names(lambda_dt) <- min(t_i):max(t_i)
lambda_dt$child_b <- family$child_b
lambda_dt <- left_join(dplyr::select(df_observed, child_b, child_name, parent_b, NodeLat, NodeLon, featureid), lambda_dt, by = "child_b")
#lambda_dt$child_b <- as.character(lambda_dt$child_b)

foo <- lambda_dt %>%
  dplyr::select(-child_name, -parent_b, -NodeLat, -NodeLon, -featureid) %>%
  tidyr::gather(key = "year", value = lambda, -child_b, convert = T)
foo$lambda <- as.numeric(foo$lambda)
# 
# child_list <- unique(df_observed$child_b)
# bar <- dplyr::filter(foo, child_b %in% child_list[1:20])

# lambda dt identical across all sites right now
ggplot(foo, aes(year, lambda*100, group = child_b, colour = child_b)) + geom_line(alpha = 0.5) + ylab("Abundance of adult Brook Trout per 100 m") + xlab("Year") + theme_bw() # + geom_jitter(position = position_jitter(width = .1), alpha = 0.5) 
```

Site specific abundance predictions when data is available. Many sites only visited once (points with no lines). Not a very informative plot other than to get a feel for the sampling.

```{r plot adult predictions site specific, echo=FALSE}
# Plot predictions
ggplot(df_observed, aes(year, N, group = child_b, colour = child_b)) + geom_point() + geom_line() + ylab("Abundance of adult Brook Trout per 100 m") + xlab("Year") + theme_bw() # + geom_jitter(position = position_jitter(width = .1), alpha = 0.5) 
```


## YOY

```{r load west susquehanna yoy results, echo=FALSE, results='hide'}
#adult_results <- readRDS("W_Susquehanna_Summary.RData")
load("W_Susquehanna_YOY_Summary.RData")
```

### Results

Compare YOY models that converged:

```{r yoy aic, echo=FALSE}
format(aic_table, digits = 2)
```

Coefficients of the top model:

```{r yoy best model summary, echo=FALSE}
LCI <- SD2b$value - (1.96 * SD2b$sd) # lower CI rough estimate for best model
UCI <- SD2b$value + (1.96 * SD2b$sd)

coef_table <- data.frame(Parameter = names(SD2b$value), Estimate = SD2b$value, SD = SD2b$sd, LCI, UCI, stringsAsFactors = FALSE)
coef_table$Parameter <- SD_table$Parameter

format(coef_table, digits = 2, scientific = 5)
```

### Plot yoy observed vs expected

```{r observed vs expected yoy, echo=FALSE}
c_ip <- df_yoy %>%
  dplyr::select(starts_with("pass"))

chat_ip <- Report2b$chat_ip
bar <- data.frame(chat_ip, row = 1:nrow(chat_ip))
bar <- gather(bar, key = row, value = chat, convert = TRUE)
sna <- data.frame(c_ip)
fu <- sna %>% gather(pass, count)
df_counts <- data.frame(fu, bar)
df_counts <- dplyr::filter(df_counts, complete.cases(df_counts))
ggplot(df_counts, aes(count, chat)) + geom_point() + geom_abline(aes(0,1), colour = "blue") + theme_bw() + xlab("Observed YOY counts per pass") + ylab("Expected YOY counts per pass")

rmse <- function(error, na.rm = T) {
  sqrt(mean(error^2, na.rm = T))
}
rmse_yoy <- rmse(df_counts$count - df_counts$chat)

```

The RMSE of observed - expected YOY counts is `r format(rmse_yoy, digits=2)`. There is no observed bias in the predicted counts compared with the observed counts.

### Plot yoy predictions

```{r plot yoy predictions, echo=FALSE}
# Plot predictions
df_observed <- df_yoy %>%
  dplyr::filter(!is.na(pass_1))

lambda_dt <- data.frame(Report2b$lambda_dt)
names(lambda_dt) <- min(t_i):max(t_i)
lambda_dt$child_b <- family$child_b
lambda_dt <- left_join(dplyr::select(df_observed, child_b, child_name, parent_b, NodeLat, NodeLon, featureid), lambda_dt, by = "child_b")
#lambda_dt$child_b <- as.character(lambda_dt$child_b)

foo <- lambda_dt %>%
  dplyr::select(-child_name, -parent_b, -NodeLat, -NodeLon, -featureid) %>%
  tidyr::gather(key = "year", value = lambda, -child_b, convert = T)
foo$lambda <- as.numeric(foo$lambda)

child_list <- unique(df_observed$child_b)
bar <- dplyr::filter(foo, child_b %in% child_list[1:20])

# lambda dt identical across all sites right now
ggplot(bar, aes(year, lambda*100, group = child_b, colour = child_b)) + geom_line() + geom_point() + ylab("Abundance of Brook Trout YOY per 100 m") + xlab("Year") + theme_bw()
```


## Discussion

**Could easily run for Brown Trout**


